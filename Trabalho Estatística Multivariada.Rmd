---
title: "Seminário - Estatística Multivaridada Computacional"
output: html_notebook
---

# Estatística Multivaridada Computacional: Teresina - Piauí

![](pca%20teresina.png)

**Gabriel Augusto Narciso Barreiros\
Adriano José de Barros\
Nelson Rios**

<https://github.com/Gabrielj96/Trabalho-R-UFMG-Multivariada>

# 0. Bibliotecas e configurações

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
library(FactoMineR)
library(factoextra)
library(corrplot)
library(ggplot2)
library(tidyverse)
library(ggcorrplot)

library(ggspatial)
#library(ggsn)
library(raster)
#library(rgdal)
library(sf)
library(sp)
library(GGally)
library(stats)
library(maps)
library(psych)

set.seed(111)
options(scipen = 999)

df_teresina = read.csv("SES_Teresina.csv")
```

# 1. Análise Descritiva

## Tamanho populacional

Cidades maiores tendem a ser mais heterogêneas do que cidades menores. Isso significa que as análises PCA realizadas em cidades maiores são mais propensas a identificar padrões complexos e não lineares.

Seguindo essa lógica, talvez, Teresina padrão mais simples como menor variância, menores correlações e menor multicolinearidade facilitando a interpretação dos dados.

```{r echo=TRUE}
df_teresina$ID = df_teresina$area_de_ponderacao %% 100
sum(df_teresina$N)
```

```{r echo=TRUE}
subset(df_teresina[order(df_teresina$N), ], select = c('ID', 'N'))
```

## Vetor de médias

### Saneamento

Analisando as variáveis de saneamento percebemos que a cidade tem um bom sistema de água encanada, atingindo um total de 99% de encaneamento de água e não ficando abaixo de 95%.

Já o sistema de esgoto com 88% fica um pouco abaixo, mas nada que podemos considerar ruim. Talvez uma enfâse na rede pública pudesse melhorar a situação.

```{r echo=TRUE}
lab.corr_saneamento = c('P_AGUAENC', 'P_AGUAENCDENTRO', 'P_AGUAREDE', 'P_ESGOTOPUB', 'P_ESGOTOQUAL')
lab.corr_moradia = c('P_MATPAREDES', 'P_OVERCROWDING')
lab.corr_emprego = c('P_DESEMP', 'P_FORTRAB')
lab.corr_educacao = c('P_ENSFUND', 'P_ENSMED', 'P_ENSSUP', 'P_FREQESCOLA')

lab.corr = c('P_AGUAENC', 'P_AGUAENCDENTRO', 'P_AGUAREDE', 'P_ESGOTOPUB', 'P_ESGOTOQUAL',
             'P_MATPAREDES', 'P_OVERCROWDING',
             'P_DESEMP', 'P_FORTRAB',
             'P_ENSFUND', 'P_ENSMED', 'P_ENSSUP', 'P_FREQESCOLA')

data.frame(as.matrix(colMeans(df_teresina[, lab.corr_saneamento]), 2))
```

### Moradia

Analisando as variáveis de moradia é perceptível que a cidade não tem muitos problemas com isso. 95% da população tem algum tipo de moradia e apenas 5% com mais de 3 pessoas no lar.

```{r}
data.frame(as.matrix(colMeans(df_teresina[, lab.corr_moradia]), 2))
```

### Emprego

Considerando que 7% de desemprego é considerado pleno emprego no Brasil, Teresina com 9% ainda tem um pouco a melhorar.

De acordo com a Organização Internacional do Trabalho (OIT), uma taxa de participação da força de trabalho de 60% ou mais é considerada elevada. Seguindo esse parâmetro Teresina está acima da média com 65%.

```{r}
data.frame(as.matrix(colMeans(df_teresina[, lab.corr_emprego]), 2))
```

### Educação

A cidade tem boa parte da população frequentando a escola (89%), mas essa taxa cai consideravelmente ao aumentar o nível de escolaridade, chegando a 15% no ensino superior. O que da espaço para políticas públicas para a educação.

```{r}
data.frame(as.matrix(colMeans(df_teresina[, lab.corr_educacao]), 2))
```

## Matriz de correlação

### Educação vs Overcrowding = Correlação Negativa

Quanto menor a educação, maior o número de residências com superlotação.

### Overcrowding vs Material Paredes = Correlação Negativa

Quanto maior o número de residências com superlotação, menor o número de domicílios com paredes feitas de materiais duráveis.

### Educação vs Material Paredes = Correlação Positiva

Quanto maior a educação, maior o número de residências com paredes feitas de materiais duráveis.

### Educação vs Esgoto = Correlação Positiva

Quanto maior a educação, maior o acesso a esgoto.

### Material Paredes vs Residência Encanada = Correlação Positiva

Quanto mais residências com paredes de materiais duráveis, mais residências encanadas.

### Educação vs Residência Encanada = Correlação Positiva

Quanto maior a educação, mais residências encanadas.

```{r echo=TRUE}
ggcorrplot(cor(df_teresina[, lab.corr]), type = "lower", outline.color = "white",
           lab = TRUE, lab_size = 2)
```

# 2. Análise Qualitativa PCA

```{r}
df_teresina_scaled = scale(subset(df_teresina, select = -c(UF, municipality, code, ID,
                                                           area_de_ponderacao, N)))
PCA = princomp(df_teresina_scaled)
summary(PCA)
```

O primeiro componente explica 59.8% da variância total, enquanto o segundo 12% e o terceiro 9.1%.

E segundo a regra de Kaiser os primeiros 3 componentes, 81% da variação, podem precisamente representar os dados.

```{r}
screeplot(PCA, main = 'Scree Plot (dashed line = Kaiser rule)', type = 'l')
abline(h = 1, lty = 2)

fviz_eig(PCA, 
         addlabels = TRUE,
         main="Figure 2") +
         geom_hline(yintercept=7, 
         linetype="dashed", 
         color = "red")
```

### Proximidade

As variáveis com maior proximidade são os educação e acesso a sistema de esgoto, ou seja, o acesso a educação está relacionada com acesso à algum tipo de sistema de esgoto na residência.

### Distância

As variáveis com maior distância são superlotação e educação, ou seja, o acesso a educação está inversamente relacionada com a superlotação nas residências.

Também percebemos a distância entre a taxa de desemprego, encanamento e frequência escolar. O aumento da taxa de desemprego está relacionada negativamente com esses problemas sociais.

### Distância da Origem e Coloração

Com base na distância da variável em relação ao centro do gráfico percebemos que as variáveis mais bem representadas por esses componentes principais são: educação e saneamento.

```{r}
fviz_pca_var(PCA, col.var = "cos2", gradient.cols = c("red", "grey", "green"))
```

# 3. Análise Qualitativa EFA

```{r}
df_teresina_efa = subset(df_teresina, select = -c(UF, municipality, code, ID,
                                                           area_de_ponderacao, N))
```

### Critério de Kaiser--Meyer--Olkin

Segundo o critério de Kaiser, podemos questionar se análise fatorial é a mais adequada para esses dados já que o teste retornou MSA = 0.5.

Um número baixo significa que as variáveis analisadas não apresentam correlações fortes o suficiente para serem agrupadas em fatores, 0.5 é um valor aceitável, porém não tão alto.

```{r}
KMO(df_teresina_efa)
```

### Scree Plots

O gráfico mostra que a curva dos dados reais (linha azul) se aproxima da curva de scree após o quarto fator. Isso sugere que os primeiros quatro fatores explicam a maior parte da variação nos dados.

```{r message=FALSE, warning=FALSE}

fa.parallel(df_teresina_efa, fa="fa")
```

### Análise Fatorial

O scree plot sugere que 4 ou 5 fatores são capazes de explicar boa proporção da variância dos dados.

A regra de Kaiser indica apenas 3 fatores, e 3 fatores explicam apenas 72% da variação total.

Já 5 fatores explicam 83% da variação total, porém o p-valor fica um tanto alto. Neste caso podemos aceitar 72% de explicação da variação total e um p-valor menor com 3 fatores.

```{r}
EFA = factanal(df_teresina_efa, factors = 5, scores = 'regression', nstart = 100)
EFA
```

```{r}
EFA = factanal(df_teresina_efa, factors = 3, scores = 'regression', nstart = 100)
EFA$PVAL
```

### Gráfico de Análise Fatorial

Podemos interpretar os fatores da seguinte forma:

-   **Fator 1:** Educação, saneamento, moradia e emprego

-   **Fator 2:** Saneamento, moradia

-   **Fator 3:** Educação e emprego

```{r}
fa.diagram(EFA$loadings)
```

# 4. Efeitos das Regras de Seleção

### Regras de seleção PCA

Uma regra comum é selecionar o número de componentes que explicam uma certa porcentagem da variância total (75%).

Por exemplo, utilizamos essa regra e obtivemos PCA que explica 81% da variação e apenas 3 componentes. Considero um bom resultado com poucas variáveis considerando a quantidade na base de dados.

No entanto, esta regra pode levar à seleção de um número excessivo de componentes se as variáveis originais estiverem altamente correlacionadas.

Outra regra comum é selecionar o número de componentes com base na regra de Kaiser.

No caso dos nossos dados o número de componentes seria o mesmo nas duas regras, mas ela pode levar a escolher um número insuficiente de componentes.

### Regras de seleção EFA

Uma regra comum é selecionar o número de componentes que explicam uma certa porcentagem da variância total (75%).

No caso dos dados de Teresina utilizamos a **Regra do scree plot** + **Teste de hipótese** isso nos ajuda a obter uma Análise Fatorial mais confiável, combinando % de variação e significância da análise.

**Resultado:** Variação Total Explicada = 72%, P-valor = 0.18.

Poderíamos ter utilizado a **Regra da porcentagem da variância explicada** o que nos traria maior explição da variação total, mas com confiabiliade menor já que o P-valor se elevaria bastante.

# 5. Índice de Status Socioeconômico

### Índice Geral PCA

```{r}
pca_index = data.frame(PCA$loadings[, 1:3])
summary(pca_index)
median(as.matrix(pca_index))
```

### Índice Geral EFA

```{r}
efa_index = data.frame(EFA$loadings[, 1:3])
summary(efa_index)
median(as.matrix(efa_index))
```
